{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c63fea8",
   "metadata": {},
   "source": [
    "\t### Text Question answer\n",
    "This code uses a pretrained AI model to answer a question based on a given passage of text (extractive question answering). Here’s a clear, step-by-step explanation.\n",
    "\n",
    " \t•\ttorch → runs the neural network\n",
    "\t•\ttransformers → library from Hugging Face\n",
    "\t•\tAutoModelForQuestionAnswering → loads a model trained to find answers inside text\n",
    "\t•\tAutoTokenizer → converts text into tokens the model understands\n",
    "\t•\tpipeline → simplifies inference into a single call\n",
    "\t•\tA DistilBERT model\n",
    "\t•\tFine-tuned on the SQuAD dataset\n",
    "\t•\tDesigned for extractive QA (the answer must appear in the context text)\n",
    "\t•\tTokenizer breaks text into subwords\n",
    "\t•\tModel learns which span of text best answers the question\n",
    "\t•\t.to(\"mps\") runs inference on Apple Silicon GPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9084f5e4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e289b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a80581bb3b4bd8aa038801f01410a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9db1321ad9be4d898c91b3c49d0fd507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/451 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a05967a8aa7042a7999e914a119c6cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c22ec61c4349119dd639b0a60b3867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "534b5f19ac9d4e419a8b3857558e685c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/265M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline, AutoModelForQuestionAnswering, AutoTokenizer\n",
    "\n",
    "model_id =\"distilbert-base-uncased-distilled-squad\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_id).to(\"mps\")\n",
    "\n",
    "qa = pipeline(\"question-answering\", model=model, tokenizer=tokenizer, device=\"mps\")\n",
    "context = (\"\"\"The ocean covers 70% of the earth's surface and is vital to life on our planet\n",
    "                It regulates climate, provides food, and supports vasts array of biodiversity\"\"\")\n",
    "question = (\"What percentage of the earth's plannet is covered by the ocean?\")\n",
    "result = qa(question=question, context=context)\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54524846",
   "metadata": {},
   "source": [
    "This code reads a paragraph and correctly extracts the answer to a specific question from it, using a pretrained AI model running locally on your Mac."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
